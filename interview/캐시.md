# 캐시란?

- 자주 사용되는 데이터를 **임의의 공간에 저장하는 방식을 의미**한다. 데이터를 디스크가 아닌 캐시 공간에서 조회하여 더 빠르게 데이터를 제공한다.
- 자주 변경되지 않는 데이터에 적용하는 것이 적합하다.

## 캐시 유형

- 메모리 캐싱
- 분산 캐싱
- 클라이언트 측 캐싱

### 메모리 캐싱

- **메모리에 캐시 데이터를 저장하는 방식**이다. 데이터에 접근하기 위해 디스크까지 접근하지 않기 때문에 **성능을 향상** 시킬 수 있다. 하지만 휘발성이기 때문에 서버가 종료되면 **데이터가 손실된다는 단점**이 있다.

### 분산 캐싱

- **여러 서버나 노드에 캐싱 데이터를 저장하는 방식**이다. **HA, 확장성 등을 장점**으로 가진다. 하지만 노드에 데이터가 분산되어 있기 때문에 **동기화 문제가 존재**한다.

### 클라이언트 캐싱

- 웹브라우저 같은 클라이언트 측에서 데이터를 캐싱하는 방식이다. 요청 수를 줄여 웹 애플리케이션의 성능을 향상 시키기 좋다.

### 참조 지역성의 원리
- **캐시 적중률**을 높이기 위해 자주 사용되는 데이터를 캐시에 저장하도록 해야한다. **참조 지역성의 원리**를 통해 **자주 사용되는 데이터를 캐시에 저장**합니다.
- 참조 지역성의 원리란? **CPU가 메모리에 접근할 때 주된 경향**을 바탕으로 만들어진 원리다.
	- 1. 시간 지역성 - CPU는 **최근**에 접근했던 메모리에 접근하는 경향이 있다.
		- 장점 - **반복 작업에 유리**하다. 
		- 단점 - 캐시에서 **중요한 데이터가 먼저 지워**질 수 있다.
	- 2. 공간 지역성 - CPU는 **접근한 메모리 근처**에 접근하려는 경향이 있다.
		- 장점 - **순차적 접근 방식에 유리**하다. 즉, 배열의 순차 접근에 유리하다.
		- 단점 - **랜덤 액세스에서는 캐시 적중률이 저하**된다.


[참조 지역성의 원리](https://www.geeksforgeeks.org/locality-of-reference-and-cache-operation-in-cache-memory/)


## 캐시 전략

**읽기 전략**
- **Cache-Aside**
- **Read-Through**

**쓰기 전략**
- **Write-Through**
- **Write-Behind**
- **Write-Around**

## 읽기 전략

### Cache-Aside(=Look aside)

- 캐시 관리 책임이 **애플리케이션**에게 있다.
- 요청이 오면 애플리케이션이 캐시를 먼저 탐색한다. 없으면 디스크에서 데이터를 조회한다. **즉, 캐시 미스 시 디스크에 접근한다.**
- WARNING! **일관성이 깨질 수 있는 문제가 있다. 캐시가 오래 유지될 가능성이 높다. (TTL 필요)**

![https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uaevKUkspqvc-0FjqYHq3A.png](https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uaevKUkspqvc-0FjqYHq3A.png)

> **cache warming**이란?

- 처음 캐시를 도입했을 때, **지속적으로 캐시 미스가 발생하기 때문에 DB에 성능 저하가 발생**할 수 있다. 이를 해결하기 위해 **미리 DB에서 캐시로 데이터를 밀어주는 작업**을 의미한다.

### Read-Through

- 캐시가 기본 데이터 소스로 사용된다. 캐시에 데이터가 없으면 DB에서 데이터를 조회해서 캐시에 저장한다. **즉, 캐시 미스 시 디스크에 접근한다.**
- (Cache-Aside 와의 차이점) 캐시가 DB에 바로 접근한다. 애플리케이션은 캐시에서만 데이터를 조회하고 캐시 미스 시 캐시가 DB에서 데이터를 조회해온다.
- DB가 느리거나 자주 읽지만 변경이 적을 때 사용한다.
- 애플리케이션이 캐시에만 접근하기 때문에 로직이 단순해진다.

### Cache-Aside vs Read-Through

캐시 어사이드와 리드쓰루는 모두 **캐시 미스 발생 시 DB에 접근하여 캐시를 갱신하는 방식**이다. 둘의 차이점은 **캐시 관리 주체**이다. 캐시 어사이드는 애플리케이션이 캐시를 관리하고 리드 쓰루는 캐시가 관리의 주체가 된다. 즉, 캐시 미스가 발생했을 때 **캐시가 DB에 접근하여 캐시 데이터를 갱신하거나 무효화**한다.

이 차이는 **리드 쓰루가 동기화하기 더 어려운 문제로 이어진다. 캐시 어사이드는 애플리케이션이 주체**이기 때문에 데이터가 변경될 때 **코드 레벨에서 캐시를 갱신**할 수 있다. 하지만 리드 쓰루는 주체가 캐시가 되기 때문에 데이터의 변경이 일어나도 캐시를 변경하기 어려워 일관성 문제가 유지될 수 있다.

### 그렇다면 언제 Cache-Aside? 언제 Read-Through

일반적으로 **캐시 어사이드를 많이 사용**한다. 애플리케이션 단위에서 **캐시 핸들링이 가능**하기 때문이다.

## 쓰기 전략

### Write-Through
- **쓰기 요청 시, 데이터와 캐시에 동시 저장**된다.
- 캐시에 **항상 최신 데이터가 저장**된다.
- 이중 쓰기로 쓰기 작업 속도가 느려진다.

### Write-Behind (Write-Back)

- 캐시에 먼저 쓰고 **DB엔 데이터가 늦게 쓰여진다**.
- **쓰기 작업**이 빨라진다.
- DB에 데이터가 늦게 저장되기 때문에 업데이트 되기 전에 DB에 문제가 생기면 **일관성 문제가 발생**한다.
- 쓰기 작업이 많은 데이터에 적합하다.

### Write-Around
- **DB에만 쓰기 작업을 반영하는 방식**이다.
- 캐시는 공간이 한정되어 있기 때문에 **캐시의 공간 메모리가 효율적**이게 된다.
- 캐시와 DB 데이터 간 **일관성이 깨진다**.

> **자주 사용하는 조합**
> **cache aside**와 **write-around**. 읽을 때는 캐시에서 읽고 없으면 DB를 조회해온다. 쓰기 작업 시에는 DB에만 반영한다. 
> 
> **한계**
> - **캐시와 DB 간의 일관성이 깨진다**. 읽기 작업 시에는 캐시에서만 데이터를 읽고 쓰기 작업 시에는 DB에만 반영되기 때문에 캐시와 DB의 데이터가 불일치하게 된다.
> 
> **한계 극복 방법**
> - 캐시 적용하는 데이터에 한계를 둔다.
> 	- 자주 읽지만 자주 변경되지 않는 데이터
> 	- 실시간으로 정확히 일치하지 않아도 되는 데이터. 즉, 실시간성이 떨어져도 되는 데이터
> - **TTL(Time to Live)**을 사용한다.



## 글로벌 캐싱 vs 로컬 캐싱

### 글로벌 캐싱이란?

- 로컬이 아닌 외부에 캐시 저장소를 두어 자주 사용되는 데이터를 저장하는 방식이다. redis, memcached 같은 소프트웨어가 대표적인 글로벌 캐싱 방식이다.
- **장점**
    - 외부에 데이터가 있기 때문에 애플리케이션 scale out 환경일 때, **일관된 데이터를 저장**하기 쉽다.
    - 별도의 스키마가 없기 때문에 **확장하기 쉽다.** (일관성 관리가 어렵겠지만)
- **단점**
    - 별도의 비용이 든다. (인프라 비용, 러닝 커브 등)
    - 확장 시 일관성 관리를 별도로 해야만 한다.
    - 네트워크 I/o 비용이 있다.

### 로컬 캐싱이란?

- **애플리케이션 내부의 메모리를 활용**하여 **자주 사용되는 데이터를 저장하는 방식**이다.
- **장점**
    - 메모리가 내부에 있기 때문에 성능이 향상된다.
    - 구현하기 쉽다.
- **단점**
    - scale out 환경에서 각 서버마다 캐싱 데이터가 관리된다.
    - 메모리를 사용하기 때문에 공간 메모리 효율이 저하된다.